@article{ghia,
title = {High-Re solutions for incompressible flow using the Navier-Stokes equations and a multigrid method},
journal = {Journal of Computational Physics},
volume = {48},
number = {3},
pages = {387-411},
year = {1982},
issn = {0021-9991},
doi = {https://doi.org/10.1016/0021-9991(82)90058-4},
url = {https://www.sciencedirect.com/science/article/pii/0021999182900584},
author = {U Ghia and K.N Ghia and C.T Shin},
abstract = {The vorticity-stream function formulation of the two-dimensional incompressible Navier-Stokes equations is used to study the effectiveness of the coupled strongly implicit multigrid (CSI-MG) method in the determination of high-Re fine-mesh flow solutions. The driven flow in a square cavity is used as the model problem. Solutions are obtained for configurations with Reynolds number as high as 10,000 and meshes consisting of as many as 257 × 257 points. For Re = 1000, the (129 × 129) grid solution required 1.5 minutes of CPU time on the AMDAHL 470 V/6 computer. Because of the appearance of one or more secondary vortices in the flow field, uniform mesh refinement was preferred to the use of one-dimensional grid-clustering coordinate transformations.}
}

@techreport{conj,
author = {Shewchuk, Jonathan R},
title = {An Introduction to the Conjugate Gradient Method Without the Agonizing Pain},
year = {1994},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {The Conjugate Gradient Method is the most prominent iterative method for solving sparse systems of linear equations. Unfortunately, many textbook treatments of the topic are written so that even their own authors would be mystified, if they bothered to read their own writing. For this reason, an understanding of the method has been reserved for the elite brilliant few who have painstakingly decoded the mumblings of their forebears. Nevertheless, the Conjugate Gradient Method is a composite of simple, elegant ideas that almost anyone can understand. Of course, a reader as intelligent as yourself will learn them almost effortlessly. The idea of quadratic forms is introduced and used to derive the methods of Steepest Descent, Conjugate Directions, and Conjugate Gradients. Eigenvectors are explained and used to examine the convergence of the Jacobi Method, Steepest Descent, and Conjugate Gradients. Other topics include preconditioning and the nonlinear Conjugate Gradient Method. I have taken pains to make this article easy to read. Sixty-two illustrations are provided. Dense prose is avoided. Concepts are explained in several different ways. Most equations are coupled with an intuitive interpretation.}
}
